{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d6f5e5",
   "metadata": {},
   "source": [
    "**SAAD, Maissa, 21517105.**\n",
    "\n",
    "**AKZOUN, Hafsa, 21511721.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9c352",
   "metadata": {},
   "source": [
    "**Which LLM(s) did you use for this work?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a186af",
   "metadata": {},
   "source": [
    "Chatgpt et Claude AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787f2ab-8fd8-4cfb-ab15-38ef01eb6107",
   "metadata": {
    "id": "a787f2ab-8fd8-4cfb-ab15-38ef01eb6107"
   },
   "source": [
    "# PROGRES 2025 - Mini-Projet 2\n",
    "# API Web\n",
    "\n",
    "Fabien Mathieu - fabien.mathieu@lip6.fr\n",
    "\n",
    "Sébastien Tixeuil - Sebastien.Tixeuil@lip6.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6dc16",
   "metadata": {
    "id": "dcd6dc16"
   },
   "source": [
    "The purpose of this mini-project is to work with the *Internet Movie DataBase* (IMDB) and a Python Web framework. It will involve:\n",
    "\n",
    "- Retrieve and manipulate datasets\n",
    "- Build an API to perform various tasks on the data\n",
    "- Build a website that will use the API above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51474257",
   "metadata": {},
   "source": [
    "# Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94a271",
   "metadata": {},
   "source": [
    "1. Cite your sources\n",
    "2. One file to rule them all\n",
    "3. Explain\n",
    "4. Execute your code\n",
    "\n",
    "\n",
    "https://github.com/balouf/progres/blob/main/rules.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9293e",
   "metadata": {},
   "source": [
    "# The IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ca9a8",
   "metadata": {},
   "source": [
    "[IMDB](https://www.imdb.com) allows to retrieve a part of its dataset for any non-commercial purpose. The available data and the formatting convention is described here: https://developer.imdb.com/non-commercial-datasets/\n",
    "\n",
    "We are especially interested in the data from the following files:\n",
    "- https://datasets.imdbws.com/title.principals.tsv.gz\n",
    "- https://datasets.imdbws.com/name.basics.tsv.gz\n",
    "- https://datasets.imdbws.com/title.basics.tsv.gz\n",
    "\n",
    "**Important notes**:\n",
    "- If you see *Your answer here*, that means something is expected from you.\n",
    "- To help you, the start and/or the end of a possible solution is sometimes given.\n",
    "- The content of IMDB is refreshed regularly. That means that some of the results you will compute, like the number of movies, will vary with time. This should not surprise you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d4109",
   "metadata": {},
   "source": [
    "## Exercise 1: Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb20ea6",
   "metadata": {},
   "source": [
    "Write a `download_imdb` function inspired by the `download` function seen in course, with the following modifications:\n",
    "- `download_imdb` will have one single argument, the name of the file to retrieve. Server location of the file is assumed to be https://datasets.imdbws.com/\n",
    "- If the file already exists, print a message telling that it exists and do nothing. You can use the `pathlib` module for that.\n",
    " The data files are quite big, so you will specify a directory `data_dir` where the data files will be stored/read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ac1aa",
   "metadata": {},
   "source": [
    "Prompt:\n",
    ">I would like a Python function called download_imdb which takes the name of a file that it should download and file from IMDB  dataset server at https://datasets.imdbws.com/. The function should accept an argument (the file name) and save the file into a folder called data_dir and use the pathlib module to check if that file already exists. If the file is present, then the function should print a message and return, otherwise it should download the file with requests. Session. Finally, use this function to download the files title.principals.tsv.gz, name.basics.tsv.gz, and title.basics.tsv.gz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1198a03f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:51:52.601352Z",
     "start_time": "2025-12-04T23:51:52.099347Z"
    },
    "id": "ed159520"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from requests import Session\n",
    "\n",
    "# Base URL where IMDB datasets are hosted\n",
    "base_url = \"https://datasets.imdbws.com/\"\n",
    "\n",
    "# Directory where the files will be stored\n",
    "data_dir = Path.home() / \"Downloads\"\n",
    "\n",
    "def download_imdb(file):\n",
    "    \"\"\"\n",
    "    Download a file from the IMDB dataset website if it does not already exist.\n",
    "    \"\"\"\n",
    "    # Ensure the data directory exists\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Full path of the file to be downloaded\n",
    "    file_path = data_dir / file\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if file_path.exists():\n",
    "        print(f\"{file} already exists.\")\n",
    "        return\n",
    "\n",
    "    # Create a session to download the file\n",
    "    with Session() as session:\n",
    "        url = base_url + file\n",
    "        response = session.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise error if download fails\n",
    "\n",
    "        # Write the downloaded content to the file\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "    print(f\"{file} downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce042418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:51:52.621408Z",
     "start_time": "2025-12-04T23:51:52.612897Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce042418",
    "outputId": "5c7dd0be-825a-4895-c96f-6c99cd733f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title.principals.tsv.gz already exists.\n",
      "name.basics.tsv.gz already exists.\n",
      "title.basics.tsv.gz already exists.\n"
     ]
    }
   ],
   "source": [
    "# List of IMDB files to download\n",
    "files = [\n",
    "    'title.principals.tsv.gz',\n",
    "    'name.basics.tsv.gz',\n",
    "    'title.basics.tsv.gz'\n",
    "]\n",
    "\n",
    "# Download each file\n",
    "for file in files:\n",
    "    download_imdb(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e35c25",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "The download_imdb function automatically downloads datasets from IMDb’s official public repository. To implement this function, we used: \n",
    "- Pathlib.Path classes for determining where our local copy of the IMDB data will go on disk.\n",
    "- We call the mkdir() function to make sure that we create the download folder before we try to save any files.\n",
    "- To get a fully qualified path to the file, we combine the path to the directory with the name of the file.\n",
    "- Before downloding the file, we check  if it already exists through exists() to prevent downloading it again.\n",
    "- If the file doesn't exist, we create a requests.Session and download it from the IMDB web site.\n",
    "- When the file is downloaded, it will be written out as a series of chunks in binary mode to allow efficient downloading of large files.\n",
    "\n",
    "Finally, we provide a console message indicating either the file already existed or it was downloaded successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c4b71",
   "metadata": {},
   "source": [
    "## Exercise 2: Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf0a274",
   "metadata": {},
   "source": [
    "- What is the size of the different files you retrieved? You can use Python or a file explorer, as you prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fec8b9",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21378cca",
   "metadata": {},
   "source": [
    "Prompt\n",
    "> Write a simple Python script that displays the size of several IMDB dataset files stored in a local directory. The script should use the pathlib module to access the files and print their sizes in megabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463a30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title.principals.tsv.gz: 710.77 MB\n",
      "name.basics.tsv.gz: 282.27 MB\n",
      "title.basics.tsv.gz: 205.22 MB\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    file_path = data_dir / file\n",
    "    size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a79e6",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- This script uses the pathlib module to access files.\n",
    "- stat().st_size returns the file size in bytes\n",
    "- The size is converted from bytes to megabytes\n",
    "- The script prints the size of each IMDB file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb096d5",
   "metadata": {},
   "source": [
    "As explained in https://developer.imdb.com/non-commercial-datasets/:\n",
    "- the data is stored as `tsv`, which means each text line represents a row.\n",
    "- A [gzip compression](https://docs.python.org/3/library/gzip.html) is used to reduce the size of the data on the hard drive.\n",
    "\n",
    "Large compressed files should not be uncompressed on your hard drive or fully loaded in memory.\n",
    "\n",
    "The Python [gzip module](https://docs.python.org/3/library/gzip.html) is designed so you can open a compressed file as if it was already uncompressed. For example, the following code reads 666 lines from `title.basics` and print the last line read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da56b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:51:52.629050Z",
     "start_time": "2025-12-04T23:51:52.623782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt0000671\tshort\tDesdemona\tDesdemona\t0\t1908\t\\N\t\\N\tDrama,Short\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "with gzip.open(data_dir / 'title.basics.tsv.gz', 'rt', encoding='utf8') as f:\n",
    "    for _ in range(666):\n",
    "        l = f.readline()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2ffad",
   "metadata": {},
   "source": [
    "- Write a function that read the 4 first lines of a compressed tsv file. Each line read should be converted into a list of elements and printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011838d",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c7382",
   "metadata": {},
   "source": [
    "Prompt\n",
    "\n",
    "> Write a Python function called explore(name) that reads the first four lines of a compressed TSV file (.tsv.gz).\n",
    "The function should use the gzip module to read the file without fully uncompressing it.\n",
    "Each line must be split using tabulation and converted into a list of elements, then printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7362cb0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:51:52.634324Z",
     "start_time": "2025-12-04T23:51:52.631063Z"
    },
    "id": "d743066b"
   },
   "outputs": [],
   "source": [
    "def explore(name):\n",
    "    file_path = data_dir / name\n",
    "\n",
    "    with gzip.open(file_path, 'rt', encoding='utf8') as f:\n",
    "        for _ in range(4):\n",
    "            line = f.readline()\n",
    "            elements = line.strip().split('\\t')\n",
    "            print(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498a5bb",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We wrote a function called explore that allows us to read the first four lines of a compressed IMDB TSV file. The function uses the gzip module, which makes it possible to read a compressed file as if it were already uncompressed, without loading the entire file into memory. This is important because IMDB datasets are very large. Each line read from the file represents one row of data, and we split the line using tab characters to obtain a list of elements. Finally, each list is printed so we can easily inspect the structure and content of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9a6d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:51:52.649606Z",
     "start_time": "2025-12-04T23:51:52.644626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First lines of title.principals.tsv.gz:\n",
      "['tconst', 'ordering', 'nconst', 'category', 'job', 'characters']\n",
      "['tt0000001', '1', 'nm1588970', 'self', '\\\\N', '[\"Self\"]']\n",
      "['tt0000001', '2', 'nm0005690', 'director', '\\\\N', '\\\\N']\n",
      "['tt0000001', '3', 'nm0005690', 'producer', 'producer', '\\\\N']\n",
      "First lines of name.basics.tsv.gz:\n",
      "['nconst', 'primaryName', 'birthYear', 'deathYear', 'primaryProfession', 'knownForTitles']\n",
      "['nm0000001', 'Fred Astaire', '1899', '1987', 'actor,miscellaneous,producer', 'tt0072308,tt0050419,tt0027125,tt0025164']\n",
      "['nm0000002', 'Lauren Bacall', '1924', '2014', 'actress,miscellaneous,soundtrack', 'tt0037382,tt0075213,tt0038355,tt0117057']\n",
      "['nm0000003', 'Brigitte Bardot', '1934', '\\\\N', 'actress,music_department,producer', 'tt0057345,tt0049189,tt0056404,tt0054452']\n",
      "First lines of title.basics.tsv.gz:\n",
      "['tconst', 'titleType', 'primaryTitle', 'originalTitle', 'isAdult', 'startYear', 'endYear', 'runtimeMinutes', 'genres']\n",
      "['tt0000001', 'short', 'Carmencita', 'Carmencita', '0', '1894', '\\\\N', '1', 'Documentary,Short']\n",
      "['tt0000002', 'short', 'Le clown et ses chiens', 'Le clown et ses chiens', '0', '1892', '\\\\N', '5', 'Animation,Short']\n",
      "['tt0000003', 'short', 'Poor Pierrot', 'Pauvre Pierrot', '0', '1892', '\\\\N', '5', 'Animation,Comedy,Romance']\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(f\"First lines of {file}:\")\n",
    "    explore(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f838cd31",
   "metadata": {},
   "source": [
    "- How many movie entries are present in the retrieved database?\n",
    "- How many people entries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c1a01",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9133dda4",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Explain how to count the number of movie entries and people entries in the IMDB dataset using Python.\n",
    "Then write simple Python code that reads compressed TSV files line by line using the gzip module.\n",
    "The code should count movie entries from title.basics.tsv.gz and people entries from name.basics.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2cd2e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movie entries: 734730\n",
      "Number of people entries: 14953819\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "# Count movie entries\n",
    "movie_count = 0\n",
    "\n",
    "with gzip.open(data_dir / \"title.basics.tsv.gz\", \"rt\", encoding=\"utf8\") as f:\n",
    "    header = f.readline()  # skip header\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        title_type = fields[1]\n",
    "        if title_type == \"movie\":\n",
    "            movie_count += 1\n",
    "\n",
    "print(\"Number of movie entries:\", movie_count)\n",
    "\n",
    "\n",
    "# Count people entries\n",
    "people_count = 0\n",
    "\n",
    "with gzip.open(data_dir / \"name.basics.tsv.gz\", \"rt\", encoding=\"utf8\") as f:\n",
    "    header = f.readline()  # skip header\n",
    "    for _ in f:\n",
    "        people_count += 1\n",
    "\n",
    "print(\"Number of people entries:\", people_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8987c",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- To answer these questions, we processed the IMDB datasets directly from their compressed TSV files without fully loading them into memory. For movie entries, we read the title.basics.tsv.gz file line by line and skipped the header. Each line represents one title, and we checked the titleType field to count only entries classified as movies. For people entries, we read the name.basics.tsv.gz file and counted the number of lines after the header, since each line corresponds to one person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1834e",
   "metadata": {},
   "source": [
    "## Exercise 3: Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0baa525",
   "metadata": {},
   "source": [
    "We want to study the relations between actors and movies. In particular, we focus on:\n",
    "- Actual movies (e.g. not TV shows or short movies), where the movie year is known and at least one actor/actress is credited.\n",
    "- Actors that are credited in at least one actual movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4f501",
   "metadata": {},
   "source": [
    "To start with, build a [Python set](https://docs.python.org/3/tutorial/datastructures.html#sets) that contains all movie ids (`tconst`) such that:\n",
    "- The type of movie (`titleType`) is `movie`;\n",
    "- The year (`startYear`) exists, i.e. is an integer.\n",
    "\n",
    "How many movies have you referenced in the set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f7448",
   "metadata": {},
   "source": [
    "Prompt:\n",
    "> Using the title.basics.tsv.gz IMDb dataset, build a Python set called true_movies that contains the identifiers (tconst) of all actual movies. A movie should be included only if its titleType is \"movie\" and its release year (startYear) is known, meaning it is not missing (\\N). The file should be read efficiently since it is large. Finally, compute and display the number of movie identifiers stored in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3b14be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:51:52.654961Z",
     "start_time": "2025-12-04T23:51:52.651613Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "# Path to the title.basics IMDb file\n",
    "file_path = data_dir / \"title.basics.tsv.gz\"\n",
    "\n",
    "true_movies = set()\n",
    "\n",
    "# Open the compressed TSV file\n",
    "with gzip.open(file_path, 'rt', encoding='utf8', errors='ignore') as f:\n",
    "    header = f.readline().strip().split('\\t')\n",
    "\n",
    "    # Get indices of useful columns\n",
    "    tconst_idx = header.index(\"tconst\")\n",
    "    title_type_idx = header.index(\"titleType\")\n",
    "    start_year_idx = header.index(\"startYear\")\n",
    "\n",
    "    # Read file line by line\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "\n",
    "        title_type = fields[title_type_idx]\n",
    "        start_year = fields[start_year_idx]\n",
    "\n",
    "        # Keep only movies with a known year\n",
    "        if title_type == \"movie\" and start_year != \"\\\\N\":\n",
    "            true_movies.add(fields[tconst_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c04fc45e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:52:06.537227Z",
     "start_time": "2025-12-04T23:52:06.530183Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c04fc45e",
    "outputId": "0afd8c75-eb3b-4071-b26e-6db6e909a696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626042"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145d5dd",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We use the file title.basics.tsv.gz, which contains metadata about all IMDb titles.\n",
    "- Since the file is compressed, we open it using the gzip module in text mode.\n",
    "- We create an empty Python set called true_movies to store unique movie identifiers (tconst).\n",
    "- We read the header to locate the columns tconst, titleType, and startYear.\n",
    "- For each line in the file, we keep only entries where:\n",
    "    - titleType is equal to \"movie\", and startYear is not equal to \\N, meaning the year is known.\n",
    "    - When both conditions are satisfied, we add the movie ID to the set.\n",
    "- Finally, we use len(true_movies) to count how many valid movies are included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214f16f",
   "metadata": {},
   "source": [
    "Now we want to build two lists, `movies` and `actors`:\n",
    "\n",
    "- Each element of `movies` should represent a movie, each element of `actors` an actor or actress;\n",
    "- A movie is represented by a list of three elements:\n",
    "  - The original name of the movie (`str`),\n",
    "  - The principal actors of the movie, stored as a list whose elements are integers that represent the index (position) of the actors in the list `actors`,\n",
    "  - The movie year, `startYear` (`int`);\n",
    "- An actor/actress is represented by a list of two elements:\n",
    "  - The name of the person (`str`),\n",
    "  - The movies the person acted in, stored as a list whose elements are integers that represent the index (position) of the movies in the list `movies`.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76909c4d",
   "metadata": {},
   "source": [
    "Build these two lists.\n",
    "\n",
    "A possible way to do this (this is a suggestion, not an order):\n",
    "- Initiate `movies` and `actors` as empty lists;\n",
    "- Create two auxiliary dictionary that will associate to each movie id (`tconst`) and person id (`nconst`) their position in the list;\n",
    "- Read the file `title.principals.tsv.gz` line by line:\n",
    "  - Ignore any line where the movie is not in the set `true_movies` or the `category` of the relation is not `actor` or `actress`,\n",
    "  - If the movie id `tconst` is not in the movie auxiliary index, append an empty movie to `movies` (`[\"\", [], 0]`) and update the movie auxiliary index with an entry for `tconst`,\n",
    "  - If the actor id `nconst` is not in the actor auxiliary index, append an empty actor to `actors` (`[\"\", []]`) and update the actor auxiliary index with an entry for `nconst`,\n",
    "  - Append the movie index (not `tconst`!) to the movies of the corresponding actor in `actors`,\n",
    "  - Append the actor index (not `nconst`!) to the actors of the corresponding movie in `movies`;\n",
    "- There can be a few undesired duplicates, e.g. some actors can have multiple entries for the same movies. For each actor, remove possible duplicates in the list of movies, and for each movie, remove possible duplicates in the list of actors;\n",
    "- Using `title.basics.tsv.gz` and your movie auxiliary index, populate each movie in `movies` with its correct name (`str`) and year (`int`);\n",
    "- Using `name.basics.tsv.gz` and your actor auxiliary index, populate each actor in `movies` with her correct name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3de220",
   "metadata": {},
   "source": [
    "### Prompt:\n",
    "> Using the IMDb datasets, we want to create two Python lists called movies and actors in order to represent the relationships between movies and actors. Only actual movies with a known release year (stored in the true_movies set) and relations where the category is actor or actress should be considered. Each movie must store its title, release year, and the indices of its actors, while each actor must store their name and the indices of the movies they acted in. To efficiently build these structures, auxiliary dictionaries should be used to map IMDb identifiers (tconst and nconst) to their positions in the lists. The information must be extracted from the files title.principals.tsv.gz, title.basics.tsv.gz, and name.basics.tsv.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e99bb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:52:06.543833Z",
     "start_time": "2025-12-04T23:52:06.538737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize structures\n",
    "movie_id_to_index = {}\n",
    "actor_id_to_index = {}\n",
    "movies = []\n",
    "actors = []\n",
    "\n",
    "# STEP 1: Build relations from title.principals.tsv.gz\n",
    "with gzip.open(data_dir / \"title.principals.tsv.gz\", \"rt\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "    header = f.readline().strip().split(\"\\t\")\n",
    "\n",
    "    tconst_idx = header.index(\"tconst\")\n",
    "    nconst_idx = header.index(\"nconst\")\n",
    "    category_idx = header.index(\"category\")\n",
    "\n",
    "    for line in f:\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "\n",
    "        tconst = fields[tconst_idx]\n",
    "        nconst = fields[nconst_idx]\n",
    "        category = fields[category_idx]\n",
    "\n",
    "        # Keep only valid movies and actors/actresses\n",
    "        if tconst not in true_movies:\n",
    "            continue\n",
    "        if category not in {\"actor\", \"actress\"}:\n",
    "            continue\n",
    "\n",
    "        # Add movie if new\n",
    "        if tconst not in movie_id_to_index:\n",
    "            movie_id_to_index[tconst] = len(movies)\n",
    "            movies.append([\"\", [], 0])  # [title, actors, year]\n",
    "\n",
    "        # Add actor if new\n",
    "        if nconst not in actor_id_to_index:\n",
    "            actor_id_to_index[nconst] = len(actors)\n",
    "            actors.append([\"\", []])  # [name, movies]\n",
    "\n",
    "        m_idx = movie_id_to_index[tconst]\n",
    "        a_idx = actor_id_to_index[nconst]\n",
    "\n",
    "        movies[m_idx][1].append(a_idx)\n",
    "        actors[a_idx][1].append(m_idx)\n",
    "\n",
    "# STEP 2: Remove duplicate references\n",
    "for movie in movies:\n",
    "    movie[1] = list(set(movie[1]))\n",
    "\n",
    "for actor in actors:\n",
    "    actor[1] = list(set(actor[1]))\n",
    "\n",
    "# STEP 3: Populate movie titles and years\n",
    "with gzip.open(data_dir / \"title.basics.tsv.gz\", \"rt\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "    header = f.readline().strip().split(\"\\t\")\n",
    "\n",
    "    tconst_idx = header.index(\"tconst\")\n",
    "    title_idx = header.index(\"originalTitle\")\n",
    "    year_idx = header.index(\"startYear\")\n",
    "\n",
    "    for line in f:\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        tconst = fields[tconst_idx]\n",
    "\n",
    "        if tconst in movie_id_to_index:\n",
    "            idx = movie_id_to_index[tconst]\n",
    "            movies[idx][0] = fields[title_idx]\n",
    "            movies[idx][2] = int(fields[year_idx])\n",
    "\n",
    "# STEP 4: Populate actor names\n",
    "with gzip.open(data_dir / \"name.basics.tsv.gz\", \"rt\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "    header = f.readline().strip().split(\"\\t\")\n",
    "\n",
    "    nconst_idx = header.index(\"nconst\")\n",
    "    name_idx = header.index(\"primaryName\")\n",
    "\n",
    "    for line in f:\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        nconst = fields[nconst_idx]\n",
    "\n",
    "        if nconst in actor_id_to_index:\n",
    "            idx = actor_id_to_index[nconst]\n",
    "            actors[idx][0] = fields[name_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc513d1",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. Initialization of data structures:\n",
    "We start by creating two empty lists, movies and actors, which will store our final data.\n",
    "We also create two dictionaries, movie_id_to_index and actor_id_to_index, to map IMDb IDs (tconst, nconst) to their positions in the lists. This allows fast access using indices instead of IDs.\n",
    "\n",
    "2. Reading title.principals.tsv.gz to build relations:\n",
    "We read the file line by line using gzip.open, \n",
    "For each line, we extract the movie ID (tconst), actor ID (nconst), and the category of the person.\n",
    "We keep only movies that belong to the true_movies set and people whose category is actor or actress\n",
    "\n",
    "3. Creating movies and actors only once:\n",
    "If a movie ID is not already in movie_id_to_index, we add a new empty movie entry [\"\", [], 0].\n",
    "If an actor ID is not already in actor_id_to_index, we add a new empty actor entry [\"\", []].\n",
    "This avoids creating duplicates.\n",
    "\n",
    "4. Building the links between movies and actors:\n",
    "For each valid relation:\n",
    "We add the actor index to the movie’s actor list\n",
    "We add the movie index to the actor’s movie list\n",
    "This creates a bidirectional relationship using list indices.\n",
    "\n",
    "5. Removing duplicate references:\n",
    "Some actors may appear multiple times for the same movie.\n",
    "We remove duplicates by converting the lists of indices into sets and back into lists.\n",
    "\n",
    "6. Adding movie titles and years\n",
    "We read title.basics.tsv.gz and, using the movie index dictionary, fill in the original movie title and the release year (startYear)\n",
    "\n",
    "7. Adding actor names \n",
    "Finally, we read name.basics.tsv.gz and use the actor index dictionary to fill in the real names of the actors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0e0a1",
   "metadata": {},
   "source": [
    "Manually check that your files are correct. For example, try to get the name and year of the movies Michel Blanc played in, or the actors of the first Harry Potter movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2fb0c",
   "metadata": {},
   "source": [
    "Your answer here (if everything went well, you just need to execute the two cells below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a99a258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:17.337213Z",
     "start_time": "2025-12-04T23:54:17.131204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"La fille du RER (2009), Et soudain, tout le monde me manque (2011), The Hundred-Foot Journey (2014), La meilleure façon de marcher (1976), Le routard (2025), Marie-Line et son juge (2023), Les grands ducs (1996), The Favour, the Watch and the Very Big Fish (1991), Je vous trouve très beau (2005), Papy fait de la résistance (1983), Rien ne va plus (1979), Nemo (1984), Cause toujours... tu m'intéresses! (1979), Circulez y a rien à voir! (1983), Uranus (1990), Embrassez qui vous voudrez (2002), Les nouvelles aventures d'Aladin (2015), Musée haut, musée bas (2008), Le cheval d'orgueil (1980), Nos 18 ans (2008), Les témoins (2007), Voyez comme on danse (2018), Ma femme s'appelle reviens (1982), Prospero's Books (1991), Chambre à part (1989), Madame Edouard (2004), Toxic Affair (1993), Le beaujolais nouveau est arrivé (1978), Vous n'aurez pas l'Alsace et la Lorraine (1977), La cache (2025), Viens chez moi, j'habite chez une copine (1981), Les petites victoires (2022), L'exercice de l'État (2011), Une petite zone de turbulences (2009), Un petit boulot (2016), Marche à l'ombre (1984), Les Tuche 4 (2021), Je hais les acteurs (1986), Les souvenirs (2014), Le père Noël est une ordure (1982), Le deuxième souffle (2007), Retenez-moi... ou je fais un malheur! (1984), Tenue de soirée (1986), Demi-soeur (2013), Les bronzés 3: amis pour la vie (2006), Drôle de samedi (1985), Monsieur Hire (1989), Les bronzés (1978), La gueule de l'autre (1979), Il mostro (1994), Les cadors (2022), Raid dingue (2016), Merci la vie (1991), Une nuit à l'Assemblée Nationale (1988), Les bronzés font du ski (1979), Docteur? (2019), Grosse fatigue (1994)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([f\"{movies[i][0]} ({movies[i][2]})\" for i in [a for a in actors if a[0]=='Michel Blanc'][0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c0142eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:17.473373Z",
     "start_time": "2025-12-04T23:54:17.338216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robbie Coltrane, Richard Harris, Fiona Shaw, Richard Griffiths, Rupert Grint, Emma Watson, Saunders Triplets, Harry Melling, Daniel Radcliffe, Maggie Smith'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([actors[i][0] for i in [m for m in movies if m[0].startswith('Harry Potter')][0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f946c",
   "metadata": {},
   "source": [
    "When you have successfully reached this point of the project, you can save the two lists `movies` and `actors` as compressed json files using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dcd8c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:49.794083Z",
     "start_time": "2025-12-04T23:54:17.474378Z"
    },
    "id": "27638009"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "with gzip.open(data_dir / 'movies.json.gz', 'wt', encoding='utf8') as f:\n",
    "    json.dump(movies, f)\n",
    "with gzip.open(data_dir / 'actors.json.gz', 'wt', encoding='utf8') as f:\n",
    "    json.dump(actors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ce3e4",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "This code will take our saved actors and movies and convert them to compressed JSON files.\n",
    "The json.dump function is used to serialize the Python lists into JSON format, while gzip.open compresses the files to reduce their size on disk.\n",
    "By saving the data in this format, we can restore our processed datasets quickly later without having to recalculate the relationships from the original larger versions of the IMDb files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547beb9",
   "metadata": {},
   "source": [
    "After your files have been saved, you do not need to re-execute all of the above each time your restart your notebook. Instead, you just need to reload `movies` and `actors` using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f89c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:55.097885Z",
     "start_time": "2025-12-04T23:54:49.795595Z"
    },
    "id": "10f89c03"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "with gzip.open(data_dir / 'movies.json.gz', 'rt', encoding='utf8') as f:\n",
    "    movies = json.load(f)\n",
    "with gzip.open(data_dir / 'actors.json.gz', 'rt', encoding='utf8') as f:\n",
    "    actors = json.load(f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3d410",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "This code reloads the previously saved movies and actors lists from compressed JSON files. By doing this, we can continue working with the datasets directly in memory without reprocessing the original IMDb TSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68a909",
   "metadata": {},
   "source": [
    "**Important remark:** in what follows, you will have to build functions that use the two lists a lot. You should NOT reload the lists each time you call a function. Instead, ensure that the two lists are loaded in memory and use them directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45a5b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 4: Explore again (now on the curated dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc58de6",
   "metadata": {},
   "source": [
    "- How many actors do you have in the new dataset? How many movies?\n",
    "- In average, in how many movies played an actor?\n",
    "- In average, how many actors play in a movie?\n",
    "- What is the name of the actor that played in the most movies? How many movies did he feature in?\n",
    "- What is the oldest movie in the DB?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259937c2",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefeacbf",
   "metadata": {},
   "source": [
    "- How many actors do you have in the new dataset? How many movies?\n",
    "\n",
    "Prompt\n",
    ">Using a curated IMDb dataset stored in two Python lists called movies and actors, write Python code to determine how many movies and how many actors are present in the dataset.\n",
    "The solution should be simple and suitable for a Master 1 networking student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68db6398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 492431\n",
      "Number of actors: 1263295\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of movies in the dataset\n",
    "num_movies = len(movies)\n",
    "\n",
    "# Number of actors in the dataset\n",
    "num_actors = len(actors)\n",
    "\n",
    "print(f\"Number of movies: {num_movies}\")\n",
    "print(f\"Number of actors: {num_actors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8293a09",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- To answer this question, we used the two curated lists movies and actors, which are already loaded in memory. Each element of the movies list represents one movie, and each element of the actors list represents one actor or actress. By applying the len() function to each list, we obtained the total number of movies and the total number of actors in the dataset. This method is straightforward and efficient, as it does not require reprocessing the original IMDb files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f6259",
   "metadata": {},
   "source": [
    "- In average, in how many movies played an actor?\n",
    "\n",
    "Prompt\n",
    ">Using a curated IMDb dataset stored in a Python list called actors, write Python code to compute the average number of movies played by an actor.\n",
    "Each actor contains a list of movie indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcaf92e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of movies per actor: 3.00\n"
     ]
    }
   ],
   "source": [
    "# Total number of actors\n",
    "num_actors = len(actors)\n",
    "\n",
    "# Average number of movies per actor\n",
    "average_movies = sum(len(actor[1]) for actor in actors) / len(actors)\n",
    "\n",
    "print(f\"Average number of movies per actor: {average_movies:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b435a",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We computed the average number of movies played by an actor by iterating over the actors list. For each actor, the number of movies they participated in is given by the length of their movie index list. We summed these values for all actors and divided the result by the total number of actors. This calculation provides an average that describes how many movies an actor typically appears in within our curated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe6c53",
   "metadata": {},
   "source": [
    "- In average, how many actors play in a movie?\n",
    "\n",
    "Prompt\n",
    ">Using a curated IMDb dataset stored in two Python lists called movies and actors, write Python code to compute the average number of actors per movie.\n",
    "Each movie contains a list of actor indices.\n",
    "The solution should be simple and suitable for a Master 1 networking student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90163e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of actors per movie: 7.70\n"
     ]
    }
   ],
   "source": [
    "# Average number of actors per movie\n",
    "average_actors = sum(len(movie[1]) for movie in movies) / len(movies)\n",
    "\n",
    "print(f\"Average number of actors per movie: {average_actors:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66de13e",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We computed the average number of actors per movie by iterating over the movies list. Each movie contains a list of actor indices corresponding to the actors who played in it. We summed the sizes of these lists for all movies and divided the result by the total number of movies. This gives us an average value that represents how many actors typically play in a movie in our curated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287f88f",
   "metadata": {},
   "source": [
    "- What is the name of the actor that played in the most movies? How many movies did he feature in?\n",
    "\n",
    "Prompt\n",
    ">Using a curated IMDb dataset stored in a list called actors, write Python code to find the actor who played in the highest number of movies.\n",
    "Each actor contains a list of movie indices.\n",
    "Display the actor’s name and the number of movies.\n",
    "The solution should be simple and suitable for a Master 1 networking student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9e59bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor with most movies: Brahmanandam\n",
      "Number of movies: 1124\n"
     ]
    }
   ],
   "source": [
    "# Find the actor with the most movies\n",
    "max_actor = max(actors, key=lambda actor: len(actor[1]))\n",
    "\n",
    "actor_name = max_actor[0]\n",
    "movie_count = len(max_actor[1])\n",
    "\n",
    "print(f\"Actor with most movies: {actor_name}\")\n",
    "print(f\"Number of movies: {movie_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ef874",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- To answer this question, we searched for the actor who has the longest list of associated movies. Each actor in the actors list contains their name and a list of movie indices representing the movies they acted in. By selecting the actor with the maximum list length, we identified the person who played in the highest number of movies. We then displayed the actor’s name and the total number of movies they featured in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c45be",
   "metadata": {},
   "source": [
    "- What is the oldest movie in the DB?\n",
    "\n",
    "Prompt\n",
    ">Using a curated IMDb dataset stored in a list called movies, write Python code to find the oldest movie in the database.\n",
    "Each movie contains its title and release year.\n",
    "Display the movie name and its year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1f97252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest movie: Miss Jerry (1894)\n"
     ]
    }
   ],
   "source": [
    "# Find the oldest movie\n",
    "oldest_movie = min(movies, key=lambda movie: movie[2])\n",
    "\n",
    "movie_title = oldest_movie[0]\n",
    "movie_year = oldest_movie[2]\n",
    "\n",
    "print(f\"Oldest movie: {movie_title} ({movie_year})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed79ecc",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We identified the oldest movie in the database by comparing the release years of all movies stored in the movies list. Each movie contains its release year as an integer, which allows direct comparison. By selecting the movie with the smallest year value, we obtained the oldest movie in our dataset. Finally, we displayed its title and release year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56d009",
   "metadata": {},
   "source": [
    "## Exercise 5: Prepare some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756c3f5",
   "metadata": {},
   "source": [
    "Write the following functions\n",
    "- `search_movie(name: str) -> list`: return a list of movies whose name contains `name` (ignoring case). Each movie is described as a dictionary with keys `name`, `year`, and `index` (its position in `movies`)\n",
    "- `get_movie(i: int) -> dict`: returns the a json of the movie at position `i`, with following keys:\n",
    "  - `name` (`str`)\n",
    "  - `year` (`int`)\n",
    "  - `actors` (list of dictionaries with keys `name` and `index`)\n",
    "- `search_actor(name: str) -> list`: return a list of actors whose name contains `name` (ignoring case). Each actor is described as a dictionary with keys `name` and `index` (its position in `actor`)\n",
    "- `get_actor(i: int) -> dict`: returns the a json of the actor at position `i`, with following keys:\n",
    "  - `name` (`str`)\n",
    "  - `movies` (list of dictionaries with keys `name`, `year`, and `index`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab0e35",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Using a curated IMDb dataset stored in a list called movies, write a Python function search_movie(name) that returns all movies whose name contains the given string, ignoring case.\n",
    "Each result should be a dictionary with keys name, year, and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37fe3e43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:55.701139Z",
     "start_time": "2025-12-04T23:54:55.697677Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_movie(name):\n",
    "    results = []\n",
    "    name = name.lower()\n",
    "\n",
    "    for i, movie in enumerate(movies):\n",
    "        if name in movie[0].lower():\n",
    "            results.append({\n",
    "                \"name\": movie[0],\n",
    "                \"year\": movie[2],\n",
    "                \"index\": i\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20324858",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We implemented the search_movie function to find movies whose title contains a given string, ignoring case differences. We iterate over the movies list using enumerate to keep track of each movie’s index. When the searched name appears in the movie title, we store the result as a dictionary containing the movie name, its release year, and its index in the movies list. The function returns a list of all matching movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a4d88",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Using a curated IMDb dataset stored in two lists called movies and actors, write a Python function get_movie(i) that returns detailed information about a movie at position i.\n",
    "The result should be a dictionary containing the movie name, year, and a list of actors with their names and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b649b418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:55.709137Z",
     "start_time": "2025-12-04T23:54:55.703157Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_movie(i):\n",
    "    movie = movies[i]\n",
    "\n",
    "    return {\n",
    "        \"name\": movie[0],\n",
    "        \"year\": movie[2],\n",
    "        \"actors\": [\n",
    "            {\n",
    "                \"name\": actors[a_idx][0],\n",
    "                \"index\": a_idx\n",
    "            }\n",
    "            for a_idx in movie[1]\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e4032",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- The get_movie function returns detailed information about a movie given its index in the movies list. We extract the movie name and release year directly from the stored structure. For the actors, we iterate over the list of actor indices associated with the movie and retrieve each actor’s name from the actors list. The result is returned as a dictionary that can easily be converted to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdbe77",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Using a curated IMDb dataset stored in a list called actors, write a Python function search_actor(name) that returns all actors whose name contains the given string, ignoring case.\n",
    "Each result should be a dictionary with keys name and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0caa9a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:55.715650Z",
     "start_time": "2025-12-04T23:54:55.711144Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_actor(name):\n",
    "    results = []\n",
    "    name = name.lower()\n",
    "\n",
    "    for i, actor in enumerate(actors):\n",
    "        if name in actor[0].lower():\n",
    "            results.append({\n",
    "                \"name\": actor[0],\n",
    "                \"index\": i\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d020e",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We created the search_actor function to find actors whose name contains a given string, without considering case sensitivity. We iterate over the actors list and compare the searched name with each actor’s name. When a match is found, we return the actor’s name and index as a dictionary. This function is useful for locating actors before retrieving detailed information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba04c2a",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Using a curated IMDb dataset stored in two lists called actors and movies, write a Python function get_actor(i) that returns detailed information about an actor at position i.\n",
    "The result should include the actor name and a list of movies with their names, years, and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a0fc883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:55.723820Z",
     "start_time": "2025-12-04T23:54:55.717809Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_actor(i):\n",
    "    actor = actors[i]\n",
    "\n",
    "    return {\n",
    "        \"name\": actor[0],\n",
    "        \"movies\": [\n",
    "            {\n",
    "                \"name\": movies[m_idx][0],\n",
    "                \"year\": movies[m_idx][2],\n",
    "                \"index\": m_idx\n",
    "            }\n",
    "            for m_idx in actor[1]\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f64c0f",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- The get_actor function returns detailed information about an actor using their index in the actors list. We retrieve the actor’s name and then iterate over the list of movie indices associated with this actor. For each movie, we extract its name, release year, and index from the movies list. The function returns a dictionary that clearly describes the actor and their filmography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d846d30a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:55.918695Z",
     "start_time": "2025-12-04T23:54:55.752880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Les bronzés', 'year': 1978, 'index': 54000},\n",
       " {'name': 'Les bronzés font du ski', 'year': 1979, 'index': 55034},\n",
       " {'name': 'Les bronzés 3: amis pour la vie', 'year': 2006, 'index': 180714},\n",
       " {'name': \"Les P'tits Bronzés au Pyrénéen\", 'year': 2013, 'index': 467203}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronzés = search_movie('bronzés')\n",
    "bronzés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91a3640e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:56.092158Z",
     "start_time": "2025-12-04T23:54:55.920703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Le gendarme de Saint-Tropez', 'year': 1964, 'index': 41008},\n",
       " {'name': 'Le gendarme à New York', 'year': 1965, 'index': 42676},\n",
       " {'name': 'Le gendarme se marie', 'year': 1968, 'index': 44459},\n",
       " {'name': 'Le gendarme en balade', 'year': 1970, 'index': 46407},\n",
       " {'name': 'Le gendarme et les extra-terrestres', 'year': 1979, 'index': 55248},\n",
       " {'name': 'Le gendarme et les gendarmettes', 'year': 1982, 'index': 58345},\n",
       " {'name': 'Le gendarme de Champignol', 'year': 1959, 'index': 92832},\n",
       " {'name': 'El gendarme desconocido', 'year': 1941, 'index': 94280},\n",
       " {'name': 'El gendarme de la esquina', 'year': 1951, 'index': 116189},\n",
       " {'name': 'Sacrés gendarmes', 'year': 1980, 'index': 120031},\n",
       " {'name': \"Hainburg - Je t'aime, gendarme\", 'year': 2001, 'index': 145905},\n",
       " {'name': 'Le gendarme de Abobo', 'year': 2019, 'index': 320666},\n",
       " {'name': 'Le retour du gendarme de Abobo', 'year': 2025, 'index': 399577}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_movie('gendarme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6254268d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:56.231422Z",
     "start_time": "2025-12-04T23:54:56.094168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Ils sont fous ces sorciers',\n",
       " 'year': 1978,\n",
       " 'actors': [{'name': 'Renée Saint-Cyr', 'index': 23809},\n",
       "  {'name': 'Catherine Lachens', 'index': 99393},\n",
       "  {'name': 'Michel Peyrelon', 'index': 85249},\n",
       "  {'name': 'Jean Lefebvre', 'index': 25385},\n",
       "  {'name': 'Jean-Jacques Moreau', 'index': 96009},\n",
       "  {'name': 'Maitena Galli', 'index': 81806},\n",
       "  {'name': 'Henri Guybet', 'index': 84594},\n",
       "  {'name': 'Julien Guiomar', 'index': 72018},\n",
       "  {'name': 'Daniel Ceccaldi', 'index': 49814},\n",
       "  {'name': 'Dominique Vallée', 'index': 244190}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie(search_movie('Ils sont fous')[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b4bdb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:56.238217Z",
     "start_time": "2025-12-04T23:54:56.232730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Les bronzés',\n",
       " 'year': 1978,\n",
       " 'actors': [{'name': 'Michel Creton', 'index': 72836},\n",
       "  {'name': 'Marie-Anne Chazel', 'index': 103879},\n",
       "  {'name': 'Bruno Moynot', 'index': 103880},\n",
       "  {'name': 'Thierry Lhermitte', 'index': 103881},\n",
       "  {'name': 'Gérard Jugnot', 'index': 98987},\n",
       "  {'name': 'Michel Blanc', 'index': 99340},\n",
       "  {'name': 'Josiane Balasko', 'index': 101299},\n",
       "  {'name': 'Luis Rego', 'index': 84374},\n",
       "  {'name': 'Martin Lamotte', 'index': 103319},\n",
       "  {'name': 'Dominique Lavanant', 'index': 103318}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie(bronzés[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5386b177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:56.528122Z",
     "start_time": "2025-12-04T23:54:56.240224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Daniel Radcliffe', 'index': 278107}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harry = search_actor('Daniel Radcliffe')\n",
    "harry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "910c6cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:56.535337Z",
     "start_time": "2025-12-04T23:54:56.529634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Daniel Radcliffe',\n",
       " 'movies': [{'name': 'Harry Potter and the Deathly Hallows: Part 2',\n",
       "   'year': 2011,\n",
       "   'index': 227081},\n",
       "  {'name': 'Imperium', 'year': 2016, 'index': 427767},\n",
       "  {'name': 'Merrily We Roll Along', 'year': 2025, 'index': 376853},\n",
       "  {'name': 'Swiss Army Man', 'year': 2016, 'index': 416535},\n",
       "  {'name': 'Horns', 'year': 2013, 'index': 268697},\n",
       "  {'name': 'Playmobil: The Movie', 'year': 2019, 'index': 419105},\n",
       "  {'name': 'Victor Frankenstein', 'year': 2015, 'index': 299172},\n",
       "  {'name': 'Beast of Burden', 'year': 2018, 'index': 449081},\n",
       "  {'name': 'Weird: The Al Yankovic Story', 'year': 2022, 'index': 284476},\n",
       "  {'name': 'National Theatre Live: Rosencrantz & Guildenstern Are Dead',\n",
       "   'year': 2017,\n",
       "   'index': 457663},\n",
       "  {'name': 'Harry Potter and the Half-Blood Prince',\n",
       "   'year': 2009,\n",
       "   'index': 175169},\n",
       "  {'name': 'The Woman in Black', 'year': 2012, 'index': 276673},\n",
       "  {'name': 'The F Word', 'year': 2013, 'index': 263620},\n",
       "  {'name': 'Jungle', 'year': 2017, 'index': 405573},\n",
       "  {'name': 'Harry Potter and the Deathly Hallows: Part 1',\n",
       "   'year': 2010,\n",
       "   'index': 196947},\n",
       "  {'name': 'Now You See Me 2', 'year': 2016, 'index': 366422},\n",
       "  {'name': 'Harry Potter and the Order of the Phoenix',\n",
       "   'year': 2007,\n",
       "   'index': 165598},\n",
       "  {'name': 'Guns Akimbo', 'year': 2019, 'index': 458335},\n",
       "  {'name': \"Harry Potter and the Sorcerer's Stone\",\n",
       "   'year': 2001,\n",
       "   'index': 124512},\n",
       "  {'name': 'The Lost City', 'year': 2022, 'index': 242144},\n",
       "  {'name': 'Lost in London', 'year': 2017, 'index': 451299},\n",
       "  {'name': 'Harry Potter and the Chamber of Secrets',\n",
       "   'year': 2002,\n",
       "   'index': 143846},\n",
       "  {'name': 'The Tailor of Panama', 'year': 2001, 'index': 122983},\n",
       "  {'name': 'Harry Potter and the Goblet of Fire',\n",
       "   'year': 2005,\n",
       "   'index': 153708},\n",
       "  {'name': 'Kill Your Darlings', 'year': 2013, 'index': 239343},\n",
       "  {'name': 'Escape from Pretoria', 'year': 2020, 'index': 443505},\n",
       "  {'name': 'December Boys', 'year': 2007, 'index': 184182},\n",
       "  {'name': 'Harry Potter and the Prisoner of Azkaban',\n",
       "   'year': 2004,\n",
       "   'index': 145911}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_actor(harry[0]['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7ed05",
   "metadata": {},
   "source": [
    "Write a function `movie_path(origin: int, destination: int) -> distance: int, path: list` that computes the collaboration distance between two actors. That distance is the length of the shortest path `(origin, act1, act2, ..., actX, destination)`, where `origin` and `act` played in the same movie, `act1` and `act2` played in the same movie, ... and\n",
    "`actX` and `destination` played in the same movie.  In addition to the distance, the response should include one shortest path between the two actors, as a list of the form `[\"origin_name\", \"movie1_name\", \"act1_name\", \"movie2_name\", ..., \"destination_name\"]`, where `movie1` is a movie that featured `origin` and `act1`, and so on...\n",
    "\n",
    "In particular:\n",
    "- One actor is by convention at distance 0 from herself. The return path should be `[\"origin_name\"]` then;\n",
    "- Two distinct actors that play in the same movie are at distance 1;\n",
    "- If there is no connection between two actors, the function should return `-1, []` by convention.\n",
    "\n",
    "**Important remarks**: `movie_path` is tricky. You need to try to implement it but you are allowed to fail. If you are stuck for too long, please explain what you did/try and what blocked you in your opinion. Then move on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c0696",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Using a curated IMDb dataset stored in two Python lists called actors and movies, write a Python function movie_path(origin, destination) that computes the shortest collaboration path between two actors.\n",
    "The function should return the collaboration distance and one shortest path, alternating actor names and movie names.\n",
    "If the origin and destination are the same actor, return distance 0 and the actor name.\n",
    "If no path exists, return -1 and an empty list.\n",
    "The solution should be suitable for a Master 1 networking student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04493bcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:56.541015Z",
     "start_time": "2025-12-04T23:54:56.537346Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def movie_path(origin, destination):\n",
    "    # Case 1: same actor\n",
    "    if origin == destination:\n",
    "        return 0, [actors[origin][0]]\n",
    "\n",
    "    visited = set()\n",
    "    queue = deque()\n",
    "    \n",
    "    # parent dictionary:\n",
    "    # actor_index -> (previous_actor_index, movie_index)\n",
    "    parent = {}\n",
    "\n",
    "    # Initialize BFS\n",
    "    queue.append(origin)\n",
    "    visited.add(origin)\n",
    "\n",
    "    while queue:\n",
    "        current_actor = queue.popleft()\n",
    "\n",
    "        # Explore movies of the current actor\n",
    "        for movie_idx in actors[current_actor][1]:\n",
    "            for next_actor in movies[movie_idx][1]:\n",
    "\n",
    "                if next_actor in visited:\n",
    "                    continue\n",
    "\n",
    "                visited.add(next_actor)\n",
    "                parent[next_actor] = (current_actor, movie_idx)\n",
    "\n",
    "                # Destination found\n",
    "                if next_actor == destination:\n",
    "                    # Reconstruct path\n",
    "                    path = [actors[destination][0]]\n",
    "                    dist = 0\n",
    "                    cur = destination\n",
    "\n",
    "                    while cur != origin:\n",
    "                        prev_actor, movie_used = parent[cur]\n",
    "                        path.append(movies[movie_used][0])\n",
    "                        path.append(actors[prev_actor][0])\n",
    "                        cur = prev_actor\n",
    "                        dist += 1\n",
    "\n",
    "                    path.reverse()\n",
    "                    return dist, path\n",
    "\n",
    "                queue.append(next_actor)\n",
    "\n",
    "    # No connection found\n",
    "    return -1, []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdea765",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- We implemented the movie_path function using a breadth-first search algorithm, which is well suited for finding the shortest path in a graph. In our case, actors are nodes and a connection exists when two actors played in the same movie. We start from the origin actor and explore all reachable actors level by level. To reconstruct the collaboration path, we store for each visited actor the previous actor and the movie that connects them. When the destination actor is found, we rebuild the path by going backwards and alternating actor names and movie names. If both actors are the same, we return a distance of zero. If no connection exists, we return -1 and an empty path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "618d8d56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:56.857335Z",
     "start_time": "2025-12-04T23:54:56.558701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Jean Dujardin', 'index': 330542}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jean = search_actor('jean dujardin')\n",
    "jean_index = jean[0]['index']\n",
    "jean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "094e4131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:57.171880Z",
     "start_time": "2025-12-04T23:54:56.859341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Kiefer Sutherland', 'index': 123947}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jack = search_actor('kiefer sutherland')\n",
    "jack_index = jack[0]['index']\n",
    "jack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a668c49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:57.469674Z",
     "start_time": "2025-12-04T23:54:57.173390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Kevin Bacon', 'index': 105473},\n",
       " {'name': 'Kevin Bacon', 'index': 1209088}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kevin = search_actor('kevin bacon')\n",
    "kevin_index = kevin[0]['index']\n",
    "kevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd4c5a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:57.861548Z",
     "start_time": "2025-12-04T23:54:57.471186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Louis de Funès', 'index': 38580}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cruchot = search_actor('louis de funès')\n",
    "cruchot_index = cruchot[0]['index']\n",
    "cruchot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b84573a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:57.867553Z",
     "start_time": "2025-12-04T23:54:57.862554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, ['Kevin Bacon'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_path(kevin_index, kevin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "803e62b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:58.503439Z",
     "start_time": "2025-12-04T23:54:57.869617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " ['Kevin Bacon',\n",
       "  'Wild Things',\n",
       "  'Bill Murray',\n",
       "  'The Monuments Men',\n",
       "  'Jean Dujardin'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_path(kevin_index, jean_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75aeb408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:59.685346Z",
     "start_time": "2025-12-04T23:54:58.505445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " ['Louis de Funès',\n",
       "  'Fantômas',\n",
       "  'Andrée Tainsy',\n",
       "  'Sous le sable',\n",
       "  'Charlotte Rampling',\n",
       "  'Melancholia',\n",
       "  'Kiefer Sutherland'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_path(cruchot_index, jack_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc481ff",
   "metadata": {
    "id": "8dc481ff",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 6. Provide a Web API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4781467-74ea-4954-acfc-6766d46a1997",
   "metadata": {
    "id": "e4781467-74ea-4954-acfc-6766d46a1997"
   },
   "source": [
    "Using Python and Flask, build a web server that implements the following routes:\n",
    "- `/movies/{id}` : where `id` is the index of a movie, returns the corresponding movie as a json (cf `get_movie`).\n",
    "- `/movies` : returns by default the first 100 movies. The value 100 can be modified by sending a URL parameter `limit`.\n",
    "- `/actors/{id}` : where `id` is the index of an author, returns the json of the actor (cf `get_actor`).\n",
    "- `/actors` : returns by default the first 100 actors. The value 100 can be modified by sending a URL parameter `limit`.\n",
    "- `/actors/{id}/costars` : returns the co-stars of one actor (actors that play in a same movie).\n",
    "- `/search/actors/{searchString}` : where `searchString` is a string to lookup one actor. This route should return the actors whose name contains `searchString` (for example, `/search/actors/w` returns the actors whose name contains `w` or `W`).\n",
    "- `/search/movies/{searchString}`: where `searchString` is a string, returns the list of movies whose title contains `searchString`. The route should accept a URL parameter `filter` formatted like `key1:value1,key2:value2,...`  to restrain the search to the publications where key `keyi` contains `valuei`. For example, `/search/movies/gendarme?filter=year:1964`\n",
    "should return the list of movies where the title contains `gendarme` published in 1964.\n",
    "- `/actors/{id_origin}/distance/{id_destination}` : where `id_origin`\n",
    "and `id_destination` are two actor indices, returns the collaboration distance between the two actors. In addition to the distance, the response should include one shortest path between the two actors, e.g. the json you return should be a list of two elements, one integer and one list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba559bad-da30-4081-adb1-996022a82d69",
   "metadata": {
    "id": "ba559bad-da30-4081-adb1-996022a82d69"
   },
   "source": [
    "The developed API should have the following characteristics:\n",
    "\n",
    "- All errors should have the same format.\n",
    "- In absence of error, the API should always return a `json`.\n",
    "- Each route must be documented with the return format, possible errors, and an explanation of parameters.\n",
    "- Each route that returns a list should return a maximum of 100 elements and should accept URL parameters `start` and `limit` to display `limit` elements starting from the `start`-th element. For example: `/actors` should return the first 100 authors, `/actors?start=100` displays the next 100, and `/actors?start=200&limit=2` displays the next 2 elements.\n",
    "- For each route that returns a list, the returned elements should be sortable based on a given field using a URL parameter `order`. For example: `/movies?order=year` displays the first 100 movies sorted by year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b05267",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Design and implement a REST Web API using Python and Flask to expose a curated IMDb dataset stored in two Python lists called movies and actors.\n",
    "The API must provide routes to retrieve movies and actors by index, search movies and actors by name, list movies and actors with pagination and sorting, retrieve co-stars of an actor, and compute the collaboration distance between two actors.\n",
    "All responses must be returned as JSON, and all errors must follow a uniform format.\n",
    "List endpoints must support URL parameters start, limit, and order.\n",
    "Each route should be clearly documented and implemented in a clean and readable way, suitable for a Master 1 networking student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85f2b9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting blinker>=1.9.0 (from flask)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /opt/homebrew/lib/python3.10/site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/homebrew/lib/python3.10/site-packages (from flask) (3.0.2)\n",
      "Collecting werkzeug>=3.1.0 (from flask)\n",
      "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, itsdangerous, click, blinker, flask\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [flask]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blinker-1.9.0 click-8.3.1 flask-3.1.2 itsdangerous-2.2.0 werkzeug-3.1.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a20c4466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [20/Dec/2025 16:38:39] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Dec/2025 16:38:41] \"GET /actors/0/costars HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Dec/2025 16:38:44] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# --------------------\n",
    "# Helper functions\n",
    "# --------------------\n",
    "\n",
    "def error_response(message, status=400):\n",
    "    return jsonify({\"error\": message}), status\n",
    "\n",
    "\n",
    "def get_pagination_params():\n",
    "    start = int(request.args.get(\"start\", 0))\n",
    "    limit = int(request.args.get(\"limit\", 100))\n",
    "    limit = min(limit, 100)\n",
    "    return start, limit\n",
    "\n",
    "\n",
    "def sort_list(data, key):\n",
    "    if key is None:\n",
    "        return data\n",
    "    try:\n",
    "        return sorted(data, key=lambda x: x.get(key))\n",
    "    except KeyError:\n",
    "        return data\n",
    "\n",
    "# --------------------\n",
    "# Root route\n",
    "# --------------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"\"\"\n",
    "    <h1>Hello from the Movie API!</h1>\n",
    "    <p>This work is by:</p>\n",
    "    <ul>\n",
    "        <li>SAAD, Maissa</li>\n",
    "        <li>AKZOUN, Hafsa</li>\n",
    "    </ul>\n",
    "    \"\"\"\n",
    "\n",
    "# --------------------\n",
    "# Routes: Movies\n",
    "# --------------------\n",
    "\n",
    "@app.route(\"/movies/<int:id>\")\n",
    "def api_get_movie(id):\n",
    "    if id < 0 or id >= len(movies):\n",
    "        return error_response(\"Movie not found\", 404)\n",
    "    return jsonify(get_movie(id))\n",
    "\n",
    "\n",
    "@app.route(\"/movies\")\n",
    "def api_movies():\n",
    "    start, limit = get_pagination_params()\n",
    "    order = request.args.get(\"order\")\n",
    "\n",
    "    data = [\n",
    "        {\"name\": m[0], \"year\": m[2], \"index\": i}\n",
    "        for i, m in enumerate(movies)\n",
    "    ]\n",
    "\n",
    "    data = sort_list(data, order)\n",
    "    return jsonify(data[start:start + limit])\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Routes: Actors\n",
    "# --------------------\n",
    "\n",
    "@app.route(\"/actors/<int:id>\")\n",
    "def api_get_actor(id):\n",
    "    if id < 0 or id >= len(actors):\n",
    "        return error_response(\"Actor not found\", 404)\n",
    "    return jsonify(get_actor(id))\n",
    "\n",
    "\n",
    "@app.route(\"/actors\")\n",
    "def api_actors():\n",
    "    start, limit = get_pagination_params()\n",
    "    order = request.args.get(\"order\")\n",
    "\n",
    "    data = [\n",
    "        {\"name\": a[0], \"index\": i}\n",
    "        for i, a in enumerate(actors)\n",
    "    ]\n",
    "\n",
    "    data = sort_list(data, order)\n",
    "    return jsonify(data[start:start + limit])\n",
    "\n",
    "\n",
    "@app.route(\"/actors/<int:id>/costars\")\n",
    "def api_costars(id):\n",
    "    if id < 0 or id >= len(actors):\n",
    "        return error_response(\"Actor not found\", 404)\n",
    "\n",
    "    costars = set()\n",
    "    for movie_idx in actors[id][1]:\n",
    "        for a in movies[movie_idx][1]:\n",
    "            if a != id:\n",
    "                costars.add(a)\n",
    "\n",
    "    result = [{\"name\": actors[i][0], \"index\": i} for i in costars]\n",
    "    return jsonify(result)\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Search routes\n",
    "# --------------------\n",
    "\n",
    "@app.route(\"/search/actors/<string:query>\")\n",
    "def api_search_actors(query):\n",
    "    return jsonify(search_actor(query))\n",
    "\n",
    "\n",
    "@app.route(\"/search/movies/<string:query>\")\n",
    "def api_search_movies(query):\n",
    "    results = search_movie(query)\n",
    "\n",
    "    filters = request.args.get(\"filter\")\n",
    "    if filters:\n",
    "        for f in filters.split(\",\"):\n",
    "            key, value = f.split(\":\")\n",
    "            results = [m for m in results if str(m.get(key)) == value]\n",
    "\n",
    "    return jsonify(results)\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Distance route\n",
    "# --------------------\n",
    "\n",
    "@app.route(\"/actors/<int:origin>/distance/<int:destination>\")\n",
    "def api_distance(origin, destination):\n",
    "    if origin < 0 or origin >= len(actors):\n",
    "        return error_response(\"Origin actor not found\", 404)\n",
    "    if destination < 0 or destination >= len(actors):\n",
    "        return error_response(\"Destination actor not found\", 404)\n",
    "\n",
    "    distance, path = movie_path(origin, destination)\n",
    "    return jsonify([distance, path])\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Run server\n",
    "# --------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db5cfc",
   "metadata": {},
   "source": [
    "To test this API, you can open a browser and try the following routes:\n",
    "- `/movies` - List of movies  \n",
    "- `/movies/0` - Get movie with index 0  \n",
    "- `/actors` - List of actors  \n",
    "- `/actors/0` - Get actor with index 0  \n",
    "- `/actors/0/costars` - Get costars of actor 0  \n",
    "- `/search/actors/<name>` - Search actors by name (replace `<name>` with the actor’s name)  \n",
    "- `/search/movies/<title>` - Search movies by title (replace `<title>` with the movie title)  \n",
    "- `/actors/0/distance/1` - Get distance between two actors (replace `0` and `1` with actor indices)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ff8d8",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We implemented a REST Web API using Flask to expose our curated IMDb dataset through HTTP routes. The API relies entirely on the movies and actors lists already loaded in memory, which ensures good performance and avoids unnecessary recomputation. Each route returns JSON responses only, and all errors follow a uniform structure to simplify client-side handling.\n",
    "\n",
    "- List-based routes support pagination through the start and limit parameters, with a maximum of 100 elements returned per request. Sorting is implemented using the order parameter, allowing results to be ordered by a given field such as year or name. Search routes allow partial and case-insensitive matching. Finally, the collaboration distance between two actors is computed using a breadth-first search algorithm and exposed through a dedicated route. This API design follows common best practices in web services and networking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e29ad3",
   "metadata": {
    "id": "e1e29ad3"
   },
   "source": [
    "## Exercise 7. Test a Web API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7110e2c",
   "metadata": {
    "id": "a7110e2c"
   },
   "source": [
    "Using `pytest`, write a program that checks that the API made in the previous exercise works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f540d",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b2c79",
   "metadata": {},
   "source": [
    "Prompt\n",
    ">Write a pytest suite to test a Flask API that exposes a curated IMDb dataset.\n",
    "The API has routes for movies, actors, searching, co-stars, and collaboration distances.\n",
    "Each test should: check status codes, check JSON responses, and check expected fields in the returned JSON.\n",
    "Use Flask's test_client() for testing.\n",
    "Tests should cover: getting single movies/actors, listing movies/actors with pagination and sorting, searching, co-stars, collaboration distance, and proper error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888c32a",
   "metadata": {},
   "source": [
    "We install the pytest package for the Python environment currently used by this Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1 in /Users/hafsaakzoun/Library/Python/3.10/lib/python/site-packages (from pytest) (1.2.2)\n",
      "Collecting iniconfig>=1.0.1 (from pytest)\n",
      "  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: packaging>=22 in /Users/hafsaakzoun/Library/Python/3.10/lib/python/site-packages (from pytest) (24.1)\n",
      "Collecting pluggy<2,>=1.5 (from pytest)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /Users/hafsaakzoun/Library/Python/3.10/lib/python/site-packages (from pytest) (2.18.0)\n",
      "Collecting tomli>=1 (from pytest)\n",
      "  Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading pytest-9.0.2-py3-none-any.whl (374 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: tomli, pluggy, iniconfig, pytest\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pytest]\n",
      "\u001b[1A\u001b[2KSuccessfully installed iniconfig-2.3.0 pluggy-1.6.0 pytest-9.0.2 tomli-2.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0744145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.17, pytest-9.0.2, pluggy-1.6.0 -- /opt/homebrew/opt/python@3.10/bin/python3.10\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/hafsaakzoun/Desktop/Master RES 1/PROGRES/MiniProjet\n",
      "plugins: anyio-4.6.2.post1\n",
      "collected 0 items                                                              \u001b[0m\n",
      "\n",
      "\u001b[33m============================ \u001b[33mno tests ran\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[33m =============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run pytest in verbose mode to execute tests and show detailed output\n",
    "! pytest -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d1a8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import json\n",
    "\n",
    "# We assume 'app' is the Flask app object from exercise 6\n",
    "\n",
    "@pytest.fixture\n",
    "def client():\n",
    "    with app.test_client() as client:\n",
    "        yield client\n",
    "\n",
    "# ----------------------------\n",
    "# Test single movie\n",
    "# ----------------------------\n",
    "def test_get_movie(client):\n",
    "    resp = client.get(\"/movies/0\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert \"name\" in data\n",
    "    assert \"year\" in data\n",
    "    assert \"actors\" in data\n",
    "    \n",
    "def test_get_movie_error(client):\n",
    "    resp = client.get(\"/movies/99999999\")\n",
    "    assert resp.status_code == 404\n",
    "    data = resp.get_json()\n",
    "    assert \"error\" in data\n",
    "\n",
    "# ----------------------------\n",
    "# Test movies list\n",
    "# ----------------------------\n",
    "def test_movies_list(client):\n",
    "    resp = client.get(\"/movies?start=0&limit=10&order=year\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert isinstance(data, list)\n",
    "    assert len(data) <= 10\n",
    "    assert \"name\" in data[0]\n",
    "    assert \"year\" in data[0]\n",
    "\n",
    "# ----------------------------\n",
    "# Test single actor\n",
    "# ----------------------------\n",
    "def test_get_actor(client):\n",
    "    resp = client.get(\"/actors/0\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert \"name\" in data\n",
    "    assert \"movies\" in data\n",
    "\n",
    "def test_get_actor_error(client):\n",
    "    resp = client.get(\"/actors/9999999\")\n",
    "    assert resp.status_code == 404\n",
    "    data = resp.get_json()\n",
    "    assert \"error\" in data\n",
    "\n",
    "# ----------------------------\n",
    "# Test actors list\n",
    "# ----------------------------\n",
    "def test_actors_list(client):\n",
    "    resp = client.get(\"/actors?start=0&limit=5&order=name\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert isinstance(data, list)\n",
    "    assert len(data) <= 5\n",
    "    assert \"name\" in data[0]\n",
    "\n",
    "# ----------------------------\n",
    "# Test co-stars\n",
    "# ----------------------------\n",
    "def test_costars(client):\n",
    "    resp = client.get(\"/actors/0/costars\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert isinstance(data, list)\n",
    "    if data:\n",
    "        assert \"name\" in data[0]\n",
    "        assert \"index\" in data[0]\n",
    "\n",
    "# ----------------------------\n",
    "# Test search actors\n",
    "# ----------------------------\n",
    "def test_search_actors(client):\n",
    "    resp = client.get(\"/search/actors/kevin\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert isinstance(data, list)\n",
    "    if data:\n",
    "        assert \"name\" in data[0]\n",
    "        assert \"index\" in data[0]\n",
    "\n",
    "# ----------------------------\n",
    "# Test search movies with filter\n",
    "# ----------------------------\n",
    "def test_search_movies(client):\n",
    "    resp = client.get(\"/search/movies/gendarme?filter=year:1964\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert isinstance(data, list)\n",
    "    if data:\n",
    "        assert \"name\" in data[0]\n",
    "        assert \"year\" in data[0]\n",
    "        assert int(data[0][\"year\"]) == 1964\n",
    "\n",
    "# ----------------------------\n",
    "# Test collaboration distance\n",
    "# ----------------------------\n",
    "def test_distance(client):\n",
    "    resp = client.get(\"/actors/0/distance/1\")\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.get_json()\n",
    "    assert isinstance(data, list)\n",
    "    assert len(data) == 2\n",
    "    assert isinstance(data[0], int)  # distance\n",
    "    assert isinstance(data[1], list)  # path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95b1440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test client for the Flask app\n",
    "client_instance = app.test_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87f64de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_get_movie: ✅ Passed\n",
      "test_get_movie_error: ✅ Passed\n",
      "test_movies_list: ✅ Passed\n",
      "test_get_actor: ✅ Passed\n",
      "test_get_actor_error: ✅ Passed\n",
      "test_actors_list: ✅ Passed\n",
      "test_costars: ✅ Passed\n",
      "test_search_actors: ✅ Passed\n",
      "test_search_movies: ✅ Passed\n",
      "test_distance: ✅ Passed\n"
     ]
    }
   ],
   "source": [
    "# List of all test functions\n",
    "tests = [\n",
    "    test_get_movie, test_get_movie_error, test_movies_list,\n",
    "    test_get_actor, test_get_actor_error, test_actors_list,\n",
    "    test_costars, test_search_actors, test_search_movies, test_distance\n",
    "]\n",
    "\n",
    "# Run each test\n",
    "for test in tests:\n",
    "    try:\n",
    "        test(client_instance)\n",
    "        print(f\"{test.__name__}: ✅ Passed\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"{test.__name__}: ❌ Failed\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd201785",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We wrote a pytest suite to validate the functionality of the Flask API. Using Flask’s test_client, we can simulate HTTP requests without running the server externally. Each route is tested for:\n",
    "\n",
    "Correct HTTP status codes (200 for success, 404 for missing resources)\n",
    "\n",
    "Correct JSON structure with expected keys (name, year, actors, movies)\n",
    "\n",
    "List endpoints check pagination (start, limit) and sorting (order)\n",
    "\n",
    "Search functionality is validated both for actors and movies, including filters\n",
    "\n",
    "Co-stars route is checked to ensure it returns a list of actors in the same movies\n",
    "\n",
    "Collaboration distance route is checked to ensure it returns a distance integer and a path list\n",
    "\n",
    "By using pytest fixtures and assertions, we ensure automated, repeatable testing. This approach is typical in networking and web development to validate APIs before deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa006cb",
   "metadata": {
    "id": "2aa006cb"
   },
   "source": [
    "## Exercise 8. Make a Website that uses the Web API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243ef46",
   "metadata": {
    "id": "2243ef46"
   },
   "source": [
    "Create a Python web server using Flask. Use the Web API you developed to offer the user a graphical Web interface. This interface allows the user to obtain, by entering relevant information into a Web form:\n",
    "\n",
    "- The complete list of movies and the complete list of costars of an actor, possibly sorted alphabetically. This actor can be searched beforehand using a substring of characters appearing in her name.\n",
    "- The colloration distance between two actors. As above, the actors can be searched beforehand using a substring of characters appearing in their names. Try to format a bit (not too much). For example:\n",
    "  - The collaboration distance between Kevin Bacon and Jean Dujardin is 2.\n",
    "  - Kevin bacon played in Wild things with Bill Murray;\n",
    "  - Bill Murray played in The Monuments Men with Jean Dujardin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a761576",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b5034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
